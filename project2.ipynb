{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Flight Delays For Domestic Airlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors: Ethan Bleier, Elijah Kramer, Roberto Palacios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Department of Transportation's (DOT) Bureau of Transportation Statistics (BTS) maintains performance records of domestic flights. These statistics include several interesting variables: dates, taxi times, delays, origins, destinations, departure, and arrival times. \n",
    "\n",
    "Using data analysis and various machine learning algorithms, this notebook plans to predict whether or not a flight will experience a delay. Specifically, we are interested in which predictors will play the biggest role in causing flight delays.\n",
    "\n",
    "Our main dataset is taken from [Kaggle](https://www.kaggle.com/datasets/giovamata/airlinedelaycauses/data) and represents data from 2008. However, we expect to find that many of these same patterns found in this dataset to persist today.\n",
    "\n",
    "In addition to this, we have [airport data]('https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat') and [airline data]('https://raw.githubusercontent.com/jpatokal/openflights/master/data/airlines.dat') taken from [OpenFlights.org](https://openflights.org/) to help fill in gaps in data and previous knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python/environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - check for unused imports\n",
    "\n",
    "# Module imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# scipy\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='notebook', style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = 6, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read in our main dataset. Because this file weighs in at almost 250MB and because git struggles with large files, we let kaggle provide the hosting - but this means some extra work to work with their .zip compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download .zip\n",
    "csv_url = 'https://www.kaggle.com/api/v1/datasets/download/giovamata/airlinedelaycauses'\n",
    "csv_zip = zipfile.ZipFile(io.BytesIO(requests.get(csv_url).content))\n",
    "\n",
    "# Open and load .csv\n",
    "with csv_zip.open('DelayedFlights.csv') as csv:\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "# Close zip stream\n",
    "csv_zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to read in our 2 supporting datasets, both provided by openflights ([https://openflights.org/](https://openflights.org/)) and hosted on GitHub.\n",
    "Unfortunately, these aren't formatted as nicely as our main dataset - while they're still technically valid .csvs, pandas expects to find column names in row 0 and these don't contain any. So we pass `header=None` to ensure we don't lose row 0 or end up with unexpected column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df = pd.read_csv('https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat', header=None)\n",
    "plane_df = pd.read_csv('https://raw.githubusercontent.com/jpatokal/openflights/master/data/airlines.dat', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some initial cleanup for our main dataset. First, we have a number of columns that don't seem very useful to us: so we drop these. Also, we know we plan to rely heavily on our `DepDelay` and `ArrDelay` variables - so we also drop any rows that have these missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Year', 'Unnamed: 0', 'FlightNum', 'TailNum', 'Cancelled'])\n",
    "df = df.dropna(subset=['DepDelay', 'ArrDelay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's generate some helper columns for us to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log10 is undefined for <= 0 values, so we set those NaN\n",
    "with np.errstate(divide='ignore'):\n",
    "    df['ArrDelayLog'] = np.where(df['ArrDelay'] > 0, np.log10(np.abs(df['ArrDelay'])), np.nan)\n",
    "    df['DepDelayLog'] = np.where(df['DepDelay'] > 0, np.log10(np.abs(df['DepDelay'])), np.nan)\n",
    "\n",
    "# Is flight actively delayed (not early or on-time)?\n",
    "df['IsDelayed'] = df['ArrDelay'] > 0\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our openflights data, we still don't have any column names yet. Let's set these ourselves so things are a bit easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names for airport df\n",
    "port_df.columns = ['AirportId', 'Name', 'City', 'Country', 'IATA', 'ICAO', 'Latitude', 'Longitude', 'Altitude', 'Timezone', 'DST', 'TZ', 'Type', 'Source']\n",
    "port_df = port_df.sort_index()\n",
    "\n",
    "# Assign column names for plane df\n",
    "plane_df.columns = ['AirlineId', 'ID', 'Name', 'IATA', 'ICAO', 'Callsign', 'Country', 'Active']\n",
    "plane_df = plane_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to do a bit more cleanup. For instance, we can simplify things by making sure we only care about US airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows for non-US airports, and airports without IATA codes\n",
    "port_df = port_df[port_df['Country'] == 'United States']\n",
    "port_df = port_df[port_df['IATA'] != '\\\\N']\n",
    "\n",
    "# Drop rows for non-US airlines, and airlines without IATA codes\n",
    "plane_df = plane_df[plane_df['Country'] == 'United States']\n",
    "plane_df = plane_df.dropna(subset = ['IATA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's drop any the columns we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_df = port_df.drop(columns=['Source', 'ICAO'])\n",
    "plane_df = plane_df.drop(columns=['Name', 'ICAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purely for curiosity\n",
    "contin_vars = ['DepDelay','ArrDelay','TaxiIn', 'TaxiOut', 'Distance']\n",
    "sns.heatmap(df[contin_vars].corr(), cmap = 'PRGn', vmin = -1, vmax = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While several factors may influence delays, we'd like to examine the constants in this situation rather than rely on chance incidents of weather or unexpected events. As such we'll first be looking at delays in relation to carriers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,6))\n",
    "\n",
    "median_carrier_delay = df.groupby('UniqueCarrier')[['ArrDelay', 'DepDelay']].median().sort_values(by ='ArrDelay', ascending = False)\n",
    "mean_carrier_delay = df.groupby('UniqueCarrier')[['ArrDelay', 'DepDelay']].mean().sort_values(by ='ArrDelay', ascending = False)\n",
    "\n",
    "median_carrier_delay.plot.barh(ax = ax1, title = 'Median Delay By Carrier', xlabel = 'Median Delay in Minutes');\n",
    "mean_carrier_delay.plot.barh(ax = ax2, title = 'Mean Delay By Carrier', xlabel = 'Mean Delay in Minutes');\n",
    "\n",
    "ax1.set_xlim(0,60)\n",
    "ax2.set_xlim(0,60)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delays At Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial analysis suggests that delays are closely tied to carriers. Our dataset also contains a column that relates specifically to carrier delays, which could be used to elucidate some of these figures. However, over a third of these values are null, making further evaluation much more difficult. Instead, we'll explore the relationship between airports and delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,6))\n",
    "\n",
    "dest_by_median_delay = df.groupby('Dest')[['ArrDelay','DepDelay']].median().sort_values(by = 'DepDelay', ascending = False).head(15)\n",
    "dest_by_mean_delay = df.groupby('Dest')[['ArrDelay','DepDelay']].mean().sort_values(by = 'DepDelay', ascending = False).head(15)\n",
    "\n",
    "dest_by_median_delay.plot.barh(ax = ax1, title = 'Top 10 Airports by Median Delay', xlabel = 'Median Delay in Minutes');\n",
    "dest_by_mean_delay.plot.barh(ax = ax2, title = 'Top 10 Airports by Mean Delay', xlabel = 'Mean Delay in Minutes');\n",
    "\n",
    "ax1.set_xlim(0, 80)\n",
    "ax2.set_xlim(0, 80)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here we can see that airports are quite consistent with the amount of delay each flight experiences at their terminals. However, we can see that smaller regional airports seem to be overrepresented in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,6))\n",
    "\n",
    "top_ten_airports = df[df['Dest'].isin((df['Dest'].value_counts().head(10)).index)]\n",
    "top_ten_airports.groupby('Dest')[['ArrDelay','DepDelay']].median().sort_values(by = 'DepDelay', ascending  = False).plot.barh(ax = ax1);\n",
    "\n",
    "bottom_ten_airports = df[df['Dest'].isin((df['Dest'].value_counts().sort_values().head(10)).index)]\n",
    "bottom_ten_airports.groupby('Dest')[['ArrDelay','DepDelay']].median().sort_values(by = 'DepDelay', ascending  = False).plot.barh(ax = ax2);\n",
    "\n",
    "ax1.set_title('Delays At Top 10 Most Visited Airports')\n",
    "ax1.set_xlabel('Median Delay in Minutes')\n",
    "\n",
    "ax2.set_title('Delays At Top 10 Least Visited Airports')\n",
    "ax2.set_xlabel('Median Delay in Minutes')\n",
    "\n",
    "ax1.set_xlim(0, 60)\n",
    "ax2.set_xlim(0, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might expect that busier airports are more likely to suffer flight delays but the data suggests otherwise. Smaller, regional airports appear to suffer equal or higher rates of delays when compared to high-volume airports. The main difference here lies in the consistency of the airports as the 10 most visited airports have similar rates of delay or are at least equal in their rate of arrival delay and departure delay. Low-traffic airports on the other hand vary from one another and even in their arrival and departure delays. \n",
    "\n",
    "From this information, we surmise that traffic is not a significant factor causing flight delays. As such we should look at other key variables such as the distance of each flight and the time of year the flight takes place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_sample = df[df['CRSArrTime'] < df['ArrTime']].sample(n = 1000, random_state = 42)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,6))\n",
    "\n",
    "ax1.scatter(scatter_sample['ArrDelayLog'],scatter_sample['Distance'], alpha = 0.5)\n",
    "\n",
    "\n",
    "ax1.set_ylim(0, 3000)\n",
    "ax1.set_title('Scatterplot of Arrival Delay By Distance')\n",
    "ax1.set_xlabel('Delay')\n",
    "ax1.set_ylabel('Distance')\n",
    "\n",
    "ax2.scatter(scatter_sample['DepDelayLog'],scatter_sample['Distance'], alpha = 0.5)\n",
    "\n",
    "ax2.set_ylim(0, 3000)\n",
    "ax2.set_title('Scatterplot of Departure Delay By Distance')\n",
    "ax2.set_xlabel('Delay')\n",
    "ax2.set_ylabel('Distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike departure delays, some flights show negative values for arrival delays, meaning they arrived at their destinations earlier than expected. As such, we started by isolating flights that failed to arrive on time and then took a sample of those instances. Then, we plotted the arrival delay of these flights against their distance traveled.\n",
    "\n",
    "The results show that delay times are evenly distributed regardless of the distance traveled, with outliers being the natural result of unforeseen incidents occurring occasionally.\n",
    "\n",
    "Next, we'll assess how much of an impact the time of year has on flight delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC']\n",
    "\n",
    "med_month_delay = df.groupby('Month')['ArrDelay'].median()\n",
    "mean_month_delay = df.groupby('Month')['ArrDelay'].mean()\n",
    "\n",
    "# applies months labels after grouping\n",
    "med_month_delay.index = med_month_delay.index.map(lambda x:months[x-1])\n",
    "mean_month_delay.index = mean_month_delay.index.map(lambda x:months[x-1])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (14,6))\n",
    "\n",
    "med_month_delay.sort_values().plot.barh(ax = ax1, title = 'Median Arrival Delay By Month', xlabel = 'Arrival Delay in Minutes')\n",
    "mean_month_delay.sort_values().plot.barh(ax = ax2, title = 'Mean Arrival Delay By Month', xlabel = 'Arrival Delay in Minutes')\n",
    "\n",
    "ax1.set_xlim(0, 50)\n",
    "ax2.set_xlim(0, 50)\n",
    "# applies month labels after grouping. Can't be used with sorting or requires change of label order\n",
    "# plt.yticks(ticks=range(12), labels = months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the arrival delay by month, we notice a trend in the winter and summer months. These months often see much heavier flight traffic than normal due to people taking vacations or visiting family. As a result, arrival delays tend to increase in those months and stay relatively low for the rest of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers\n",
    "plt.boxplot([df['DepDelay'], df['ArrDelay']])\n",
    "plt.xticks([1, 2], ['DepDelay', 'ArrDelay'])\n",
    "plt.show()\n",
    "\n",
    "z_scores = zscore(df[['DepDelay', 'ArrDelay']])\n",
    "outliers = (abs(z_scores) > 3).any(axis=1)\n",
    "print('Number of outliers:', outliers.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows us that there are too many outliers for the mean of the data to provide us with anything useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[['ArrDelay', 'DepDelay']]\n",
    "numeric_vars = df_num.columns.values\n",
    "\n",
    "zscore1 = lambda s: zscore(s, nan_policy='omit')\n",
    "\n",
    "df_scaled = df_num.apply(zscore1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.apply(['min', 'max']).round(2).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the min and max in this instance shows us that some delay values are negative and may indicate either flights that arrived early, or some sort of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_num);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a strong linear relationship between the departure and arrival delays, making these predictor variables useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delay prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see if we can *predict* whether a flight is going to be delayed ahead of time. Because we're predicting a boolean \"delayed/not delayed\", using a KNN classifier seems like a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, though, we have a problem: even though KNN is a relatively fast algorithm, our dataset is so large that prediction becomes prohibitively slow. So, let's randomly sample a more reasonable - but still very large - amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.sample(n=100000, random_state=0)\n",
    "print(f'Using {df_reduced.shape[0]:,} rows, reduced from {df.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's pick out some variables to use. We know we want to find out if a flight is going to be delayed, so anything with a clear relationship to that is probably going to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# Pick out features\n",
    "X = df_reduced[['UniqueCarrier', 'Dest', 'Month', 'DayOfWeek']].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "X['Dest'] = encoder.fit_transform(X['Dest'])\n",
    "X['UniqueCarrier'] = encoder.fit_transform(X['UniqueCarrier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will perform a train/test split. If we use a `test_size` of 0.1, we should still have plenty of data left for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df_reduced['IsDelayed'], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is ready, we should be able to train our KNN classifier now. This should be very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now let's see what happens when we make a prediction off our test data. How's does our classifier perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(f'Accuracy: {np.mean(y_pred == y_test):.2f}')\n",
    "print(f'Baseline accuracy: {(np.mean(y_test == True)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output some useful metrics\n",
    "print(f'Precision: {precision_score(y_test, y_pred):.2f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred):.2f}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred, average='binary'):.2f}')\n",
    "\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Delay Predicted False', 'Delay Predicted True'], yticklabels=['Actual False', 'Actual True'])\n",
    "plt.title('IsDelayed Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['Month', 'DepDelay', 'DepTime']\n",
    "target = 'ArrDelay'\n",
    "X = df[predictors].values\n",
    "y = df[target].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reger = LinearRegression()\n",
    "reger.fit(X_train, y_train)\n",
    "\n",
    "y_pred = reger.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target = y_train.mean()\n",
    "mse_baseline = ((mean_target - y_test) ** 2).mean()\n",
    "rmse_baseline = np.sqrt(mse_baseline)\n",
    "\n",
    "print(f'Baseline RMSE: {rmse_baseline:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = np.sqrt(np.mean((y_pred - y_test) ** 2))\n",
    "print(f'Test RMSE: {test_rmse:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = y_test, y = y_pred)\n",
    "plt.plot([0, 2500], [0, 2500], color = 'grey', linestyle = 'dashed')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Arrival Delay: Actual by Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['DepDelay', 'ArrDelay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,random_state=0)\n",
    "cluster_nums = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: Are the clusters too skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_nums[:100]\n",
    "\n",
    "print('Cluster 1:', np.bincount(cluster_nums)[0])\n",
    "print('Cluster 2:', np.bincount(cluster_nums)[1]) \n",
    "print('Cluster 3:', np.bincount(cluster_nums)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These clusters seem to expose an acceptable level of skewedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(kmeans.cluster_centers_, columns=['DepDelay', 'ArrDelay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = pd.DataFrame(kmeans.cluster_centers_,\n",
    "columns=['ArrDelay', 'DepDelay'])\n",
    "\n",
    "centers.plot.barh()\n",
    "plt.title('Cluster centers')\n",
    "plt.xlabel('value'); plt.ylabel('cluster number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This barplot clearly shows how each clusters are grouped, with cluster 1 being the worst and cluster 0 being the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_stats = df.groupby('Origin').agg({\n",
    "   'Distance': 'mean',\n",
    "   'CarrierDelay': 'mean'\n",
    "}).dropna()\n",
    "\n",
    "X_scaled = scaler.fit_transform(airport_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "airport_stats['Cluster'] = kmeans.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blue is decent, red is bad and blue is good airport\n",
    "colors = ['b', 'r', 'g']\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1],\n",
    "           c=[colors[i] for i in airport_stats['Cluster']],\n",
    "           s=30, alpha=0.3)\n",
    "\n",
    "distances = np.sqrt(X_scaled[:, 0]**2 + X_scaled[:, 1]**2)\n",
    "outlier_threshold = np.percentile(distances, 90)  # Top 10% is outlier threshold\n",
    "outliers = distances > outlier_threshold\n",
    "\n",
    "for i, txt in enumerate(airport_stats.index):\n",
    "    if outliers[i]:\n",
    "        plt.annotate(txt, (X_scaled[i, 0], X_scaled[i, 1]), \n",
    "                    fontsize=8, xytext=(5, 5),\n",
    "                    textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Average Flight Distance (scaled)')\n",
    "plt.ylabel('Average Airport Delay (scaled)')\n",
    "plt.title('Airport Clusters by Distance and Delay')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've plotted clusters by distance and delay. The green cluster are the best, the red cluster are the worst, and the blue cluster represents airports with mixed performance.\n",
    "\n",
    "We can see airports like LAX, SFO and HNL are in the green cluster, meaning they have exceptional performance (low delay given high distance flights).\n",
    "\n",
    "Airports like ALO, PLN and GMX perform the worst, with the highest delay times despite shorter average flight distances.\n",
    "\n",
    "We use this plot to gain a general understanding of how the airports in this dataset perform.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
